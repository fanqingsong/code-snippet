{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "StandardScaler()\n",
      "[1.         0.         0.33333333]\n",
      "[0.81649658 0.81649658 1.24721913]\n",
      "[[ 0.         -1.22474487  1.33630621]\n",
      " [ 1.22474487  0.         -0.26726124]\n",
      " [-1.22474487  1.22474487 -1.06904497]]\n"
     ]
    }
   ],
   "source": [
    "from sklearn import preprocessing\n",
    "import numpy as np\n",
    "X_train = np.array([[ 1., -1.,  2.],\n",
    "                    [ 2.,  0.,  0.],\n",
    "                    [ 0.,  1., -1.]])\n",
    "scaler = preprocessing.StandardScaler().fit(X_train)\n",
    "print(scaler)\n",
    "\n",
    "\n",
    "print(scaler.mean_)\n",
    "\n",
    "\n",
    "print(scaler.scale_)\n",
    "\n",
    "\n",
    "X_scaled = scaler.transform(X_train)\n",
    "print(X_scaled)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0. 0. 0.]\n",
      "[1. 1. 1.]\n"
     ]
    }
   ],
   "source": [
    "print(X_scaled.mean(axis=0))\n",
    "\n",
    "\n",
    "print(X_scaled.std(axis=0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.96"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.datasets import make_classification\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "X, y = make_classification(random_state=42)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=42)\n",
    "pipe = make_pipeline(StandardScaler(), LogisticRegression())\n",
    "pipe.fit(X_train, y_train)  # apply scaling on training data\n",
    "\n",
    "\n",
    "\n",
    "pipe.score(X_test, y_test)  # apply scaling on testing data, without leaking training data.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.5       , 0.        , 1.        ],\n",
       "       [1.        , 0.5       , 0.33333333],\n",
       "       [0.        , 1.        , 0.        ]])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train = np.array([[ 1., -1.,  2.],\n",
    "                    [ 2.,  0.,  0.],\n",
    "                    [ 0.,  1., -1.]])\n",
    "\n",
    "min_max_scaler = preprocessing.MinMaxScaler()\n",
    "X_train_minmax = min_max_scaler.fit_transform(X_train)\n",
    "X_train_minmax\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-1.5       ,  0.        ,  1.66666667]])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test = np.array([[-3., -1.,  4.]])\n",
    "X_test_minmax = min_max_scaler.transform(X_test)\n",
    "X_test_minmax\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.5        0.5        0.33333333]\n",
      "[0.         0.5        0.33333333]\n"
     ]
    }
   ],
   "source": [
    "print(min_max_scaler.scale_)\n",
    "\n",
    "\n",
    "print(min_max_scaler.min_)\n",
    "\n",
    "#print(min_max_scaler.max_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "unsupported operand type(s) for -: 'builtin_function_or_method' and 'builtin_function_or_method'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-11-6db8133ac739>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[0mX_std\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m \u001b[1;33m-\u001b[0m \u001b[0mX\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmin\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0maxis\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m/\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmax\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0maxis\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m-\u001b[0m \u001b[0mX\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmin\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0maxis\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 3\u001b[1;33m \u001b[0mX_scaled\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mX_std\u001b[0m \u001b[1;33m*\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mmax\u001b[0m \u001b[1;33m-\u001b[0m \u001b[0mmin\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0mmin\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m: unsupported operand type(s) for -: 'builtin_function_or_method' and 'builtin_function_or_method'"
     ]
    }
   ],
   "source": [
    "X_std = (X - X.min(axis=0)) / (X.max(axis=0) - X.min(axis=0))\n",
    "\n",
    "X_scaled = X_std * (max - min) + min"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([2., 1., 2.])"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train = np.array([[ 1., -1.,  2.],\n",
    "                    [ 2.,  0.,  0.],\n",
    "                    [ 0.,  1., -1.]])\n",
    "\n",
    "max_abs_scaler = preprocessing.MaxAbsScaler()\n",
    "X_train_maxabs = max_abs_scaler.fit_transform(X_train)\n",
    "X_train_maxabs\n",
    "\n",
    "\n",
    "\n",
    "X_test = np.array([[ -3., -1.,  4.]])\n",
    "X_test_maxabs = max_abs_scaler.transform(X_test)\n",
    "X_test_maxabs\n",
    "\n",
    "max_abs_scaler.scale_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[5.9 3.  4.2 1.5]\n",
      " [5.8 2.6 4.  1.2]\n",
      " [6.8 3.  5.5 2.1]\n",
      " [4.7 3.2 1.3 0.2]\n",
      " [6.9 3.1 5.1 2.3]\n",
      " [5.  3.5 1.6 0.6]\n",
      " [5.4 3.7 1.5 0.2]\n",
      " [5.  2.  3.5 1. ]\n",
      " [6.5 3.  5.5 1.8]\n",
      " [6.7 3.3 5.7 2.5]\n",
      " [6.  2.2 5.  1.5]\n",
      " [6.7 2.5 5.8 1.8]\n",
      " [5.6 2.5 3.9 1.1]\n",
      " [7.7 3.  6.1 2.3]\n",
      " [6.3 3.3 4.7 1.6]\n",
      " [5.5 2.4 3.8 1.1]\n",
      " [6.3 2.7 4.9 1.8]\n",
      " [6.3 2.8 5.1 1.5]\n",
      " [4.9 2.5 4.5 1.7]\n",
      " [6.3 2.5 5.  1.9]\n",
      " [7.  3.2 4.7 1.4]\n",
      " [6.5 3.  5.2 2. ]\n",
      " [6.  3.4 4.5 1.6]\n",
      " [4.8 3.1 1.6 0.2]\n",
      " [5.8 2.7 5.1 1.9]\n",
      " [5.6 2.7 4.2 1.3]\n",
      " [5.6 2.9 3.6 1.3]\n",
      " [5.5 2.5 4.  1.3]\n",
      " [6.1 3.  4.6 1.4]\n",
      " [7.2 3.2 6.  1.8]\n",
      " [5.3 3.7 1.5 0.2]\n",
      " [4.3 3.  1.1 0.1]\n",
      " [6.4 2.7 5.3 1.9]\n",
      " [5.7 3.  4.2 1.2]\n",
      " [5.4 3.4 1.7 0.2]\n",
      " [5.7 4.4 1.5 0.4]\n",
      " [6.9 3.1 4.9 1.5]\n",
      " [4.6 3.1 1.5 0.2]\n",
      " [5.9 3.  5.1 1.8]\n",
      " [5.1 2.5 3.  1.1]\n",
      " [4.6 3.4 1.4 0.3]\n",
      " [6.2 2.2 4.5 1.5]\n",
      " [7.2 3.6 6.1 2.5]\n",
      " [5.7 2.9 4.2 1.3]\n",
      " [4.8 3.  1.4 0.1]\n",
      " [7.1 3.  5.9 2.1]\n",
      " [6.9 3.2 5.7 2.3]\n",
      " [6.5 3.  5.8 2.2]\n",
      " [6.4 2.8 5.6 2.1]\n",
      " [5.1 3.8 1.6 0.2]\n",
      " [4.8 3.4 1.6 0.2]\n",
      " [6.5 3.2 5.1 2. ]\n",
      " [6.7 3.3 5.7 2.1]\n",
      " [4.5 2.3 1.3 0.3]\n",
      " [6.2 3.4 5.4 2.3]\n",
      " [4.9 3.  1.4 0.2]\n",
      " [5.7 2.5 5.  2. ]\n",
      " [6.9 3.1 5.4 2.1]\n",
      " [4.4 3.2 1.3 0.2]\n",
      " [5.  3.6 1.4 0.2]\n",
      " [7.2 3.  5.8 1.6]\n",
      " [5.1 3.5 1.4 0.3]\n",
      " [4.4 3.  1.3 0.2]\n",
      " [5.4 3.9 1.7 0.4]\n",
      " [5.5 2.3 4.  1.3]\n",
      " [6.8 3.2 5.9 2.3]\n",
      " [7.6 3.  6.6 2.1]\n",
      " [5.1 3.5 1.4 0.2]\n",
      " [4.9 3.1 1.5 0.2]\n",
      " [5.2 3.4 1.4 0.2]\n",
      " [5.7 2.8 4.5 1.3]\n",
      " [6.6 3.  4.4 1.4]\n",
      " [5.  3.2 1.2 0.2]\n",
      " [5.1 3.3 1.7 0.5]\n",
      " [6.4 2.9 4.3 1.3]\n",
      " [5.4 3.4 1.5 0.4]\n",
      " [7.7 2.6 6.9 2.3]\n",
      " [4.9 2.4 3.3 1. ]\n",
      " [7.9 3.8 6.4 2. ]\n",
      " [6.7 3.1 4.4 1.4]\n",
      " [5.2 4.1 1.5 0.1]\n",
      " [6.  3.  4.8 1.8]\n",
      " [5.8 4.  1.2 0.2]\n",
      " [7.7 2.8 6.7 2. ]\n",
      " [5.1 3.8 1.5 0.3]\n",
      " [4.7 3.2 1.6 0.2]\n",
      " [7.4 2.8 6.1 1.9]\n",
      " [5.  3.3 1.4 0.2]\n",
      " [6.3 3.4 5.6 2.4]\n",
      " [5.7 2.8 4.1 1.3]\n",
      " [5.8 2.7 3.9 1.2]\n",
      " [5.7 2.6 3.5 1. ]\n",
      " [6.4 3.2 5.3 2.3]\n",
      " [6.7 3.  5.2 2.3]\n",
      " [6.3 2.5 4.9 1.5]\n",
      " [6.7 3.  5.  1.7]\n",
      " [5.  3.  1.6 0.2]\n",
      " [5.5 2.4 3.7 1. ]\n",
      " [6.7 3.1 5.6 2.4]\n",
      " [5.8 2.7 5.1 1.9]\n",
      " [5.1 3.4 1.5 0.2]\n",
      " [6.6 2.9 4.6 1.3]\n",
      " [5.6 3.  4.1 1.3]\n",
      " [5.9 3.2 4.8 1.8]\n",
      " [6.3 2.3 4.4 1.3]\n",
      " [5.5 3.5 1.3 0.2]\n",
      " [5.1 3.7 1.5 0.4]\n",
      " [4.9 3.1 1.5 0.1]\n",
      " [6.3 2.9 5.6 1.8]\n",
      " [5.8 2.7 4.1 1. ]\n",
      " [7.7 3.8 6.7 2.2]\n",
      " [4.6 3.2 1.4 0.2]]\n",
      "[5.9 5.8 6.8 4.7 6.9 5.  5.4 5.  6.5 6.7 6.  6.7 5.6 7.7 6.3 5.5 6.3 6.3\n",
      " 4.9 6.3 7.  6.5 6.  4.8 5.8 5.6 5.6 5.5 6.1 7.2 5.3 4.3 6.4 5.7 5.4 5.7\n",
      " 6.9 4.6 5.9 5.1 4.6 6.2 7.2 5.7 4.8 7.1 6.9 6.5 6.4 5.1 4.8 6.5 6.7 4.5\n",
      " 6.2 4.9 5.7 6.9 4.4 5.  7.2 5.1 4.4 5.4 5.5 6.8 7.6 5.1 4.9 5.2 5.7 6.6\n",
      " 5.  5.1 6.4 5.4 7.7 4.9 7.9 6.7 5.2 6.  5.8 7.7 5.1 4.7 7.4 5.  6.3 5.7\n",
      " 5.8 5.7 6.4 6.7 6.3 6.7 5.  5.5 6.7 5.8 5.1 6.6 5.6 5.9 6.3 5.5 5.1 4.9\n",
      " 6.3 5.8 7.7 4.6]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\efnxqng\\AppData\\Roaming\\Python\\Python37\\site-packages\\sklearn\\preprocessing\\_data.py:2370: UserWarning: n_quantiles (1000) is greater than the total number of samples (112). n_quantiles is set to n_samples.\n",
      "  % (self.n_quantiles, n_samples))\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([4.3, 5.1, 5.8, 6.5, 7.9])"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.datasets import load_iris\n",
    "from sklearn.model_selection import train_test_split\n",
    "X, y = load_iris(return_X_y=True)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=0)\n",
    "quantile_transformer = preprocessing.QuantileTransformer(random_state=0)\n",
    "X_train_trans = quantile_transformer.fit_transform(X_train)\n",
    "X_test_trans = quantile_transformer.transform(X_test)\n",
    "\n",
    "print(X_train)\n",
    "\n",
    "print(X_train[:,0])\n",
    "\n",
    "np.percentile(X_train[:, 0], [0, 25, 50, 75, 100]) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.        , 0.23873874, 0.50900901, 0.74324324, 1.        ])"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.percentile(X_train_trans[:, 0], [0, 25, 50, 75, 100])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[4.4   5.125 5.75  6.175 7.3  ]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([0.01351351, 0.25112613, 0.47972973, 0.60472973, 0.94144144])"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(np.percentile(X_test[:, 0], [0, 25, 50, 75, 100]))\n",
    "\n",
    "\n",
    "np.percentile(X_test_trans[:, 0], [0, 25, 50, 75, 100])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1.28331718 1.18092228 0.84160269]\n",
      " [0.94293279 1.60960836 0.3879099 ]\n",
      " [1.35235668 0.21715673 1.09977091]]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[ 0.49024349,  0.17881995, -0.1563781 ],\n",
       "       [-0.05102892,  0.58863195, -0.57612414],\n",
       "       [ 0.69420009, -0.84857822,  0.10051454]])"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pt = preprocessing.PowerTransformer(method='box-cox', standardize=False)\n",
    "X_lognormal = np.random.RandomState(616).lognormal(size=(3, 3))\n",
    "print(X_lognormal)\n",
    "\n",
    "\n",
    "\n",
    "pt.fit_transform(X_lognormal)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[5.9 3.  4.2 1.5]\n",
      " [5.8 2.6 4.  1.2]\n",
      " [6.8 3.  5.5 2.1]\n",
      " [4.7 3.2 1.3 0.2]\n",
      " [6.9 3.1 5.1 2.3]\n",
      " [5.  3.5 1.6 0.6]\n",
      " [5.4 3.7 1.5 0.2]\n",
      " [5.  2.  3.5 1. ]\n",
      " [6.5 3.  5.5 1.8]\n",
      " [6.7 3.3 5.7 2.5]\n",
      " [6.  2.2 5.  1.5]\n",
      " [6.7 2.5 5.8 1.8]\n",
      " [5.6 2.5 3.9 1.1]\n",
      " [7.7 3.  6.1 2.3]\n",
      " [6.3 3.3 4.7 1.6]\n",
      " [5.5 2.4 3.8 1.1]\n",
      " [6.3 2.7 4.9 1.8]\n",
      " [6.3 2.8 5.1 1.5]\n",
      " [4.9 2.5 4.5 1.7]\n",
      " [6.3 2.5 5.  1.9]\n",
      " [7.  3.2 4.7 1.4]\n",
      " [6.5 3.  5.2 2. ]\n",
      " [6.  3.4 4.5 1.6]\n",
      " [4.8 3.1 1.6 0.2]\n",
      " [5.8 2.7 5.1 1.9]\n",
      " [5.6 2.7 4.2 1.3]\n",
      " [5.6 2.9 3.6 1.3]\n",
      " [5.5 2.5 4.  1.3]\n",
      " [6.1 3.  4.6 1.4]\n",
      " [7.2 3.2 6.  1.8]\n",
      " [5.3 3.7 1.5 0.2]\n",
      " [4.3 3.  1.1 0.1]\n",
      " [6.4 2.7 5.3 1.9]\n",
      " [5.7 3.  4.2 1.2]\n",
      " [5.4 3.4 1.7 0.2]\n",
      " [5.7 4.4 1.5 0.4]\n",
      " [6.9 3.1 4.9 1.5]\n",
      " [4.6 3.1 1.5 0.2]\n",
      " [5.9 3.  5.1 1.8]\n",
      " [5.1 2.5 3.  1.1]\n",
      " [4.6 3.4 1.4 0.3]\n",
      " [6.2 2.2 4.5 1.5]\n",
      " [7.2 3.6 6.1 2.5]\n",
      " [5.7 2.9 4.2 1.3]\n",
      " [4.8 3.  1.4 0.1]\n",
      " [7.1 3.  5.9 2.1]\n",
      " [6.9 3.2 5.7 2.3]\n",
      " [6.5 3.  5.8 2.2]\n",
      " [6.4 2.8 5.6 2.1]\n",
      " [5.1 3.8 1.6 0.2]\n",
      " [4.8 3.4 1.6 0.2]\n",
      " [6.5 3.2 5.1 2. ]\n",
      " [6.7 3.3 5.7 2.1]\n",
      " [4.5 2.3 1.3 0.3]\n",
      " [6.2 3.4 5.4 2.3]\n",
      " [4.9 3.  1.4 0.2]\n",
      " [5.7 2.5 5.  2. ]\n",
      " [6.9 3.1 5.4 2.1]\n",
      " [4.4 3.2 1.3 0.2]\n",
      " [5.  3.6 1.4 0.2]\n",
      " [7.2 3.  5.8 1.6]\n",
      " [5.1 3.5 1.4 0.3]\n",
      " [4.4 3.  1.3 0.2]\n",
      " [5.4 3.9 1.7 0.4]\n",
      " [5.5 2.3 4.  1.3]\n",
      " [6.8 3.2 5.9 2.3]\n",
      " [7.6 3.  6.6 2.1]\n",
      " [5.1 3.5 1.4 0.2]\n",
      " [4.9 3.1 1.5 0.2]\n",
      " [5.2 3.4 1.4 0.2]\n",
      " [5.7 2.8 4.5 1.3]\n",
      " [6.6 3.  4.4 1.4]\n",
      " [5.  3.2 1.2 0.2]\n",
      " [5.1 3.3 1.7 0.5]\n",
      " [6.4 2.9 4.3 1.3]\n",
      " [5.4 3.4 1.5 0.4]\n",
      " [7.7 2.6 6.9 2.3]\n",
      " [4.9 2.4 3.3 1. ]\n",
      " [7.9 3.8 6.4 2. ]\n",
      " [6.7 3.1 4.4 1.4]\n",
      " [5.2 4.1 1.5 0.1]\n",
      " [6.  3.  4.8 1.8]\n",
      " [5.8 4.  1.2 0.2]\n",
      " [7.7 2.8 6.7 2. ]\n",
      " [5.1 3.8 1.5 0.3]\n",
      " [4.7 3.2 1.6 0.2]\n",
      " [7.4 2.8 6.1 1.9]\n",
      " [5.  3.3 1.4 0.2]\n",
      " [6.3 3.4 5.6 2.4]\n",
      " [5.7 2.8 4.1 1.3]\n",
      " [5.8 2.7 3.9 1.2]\n",
      " [5.7 2.6 3.5 1. ]\n",
      " [6.4 3.2 5.3 2.3]\n",
      " [6.7 3.  5.2 2.3]\n",
      " [6.3 2.5 4.9 1.5]\n",
      " [6.7 3.  5.  1.7]\n",
      " [5.  3.  1.6 0.2]\n",
      " [5.5 2.4 3.7 1. ]\n",
      " [6.7 3.1 5.6 2.4]\n",
      " [5.8 2.7 5.1 1.9]\n",
      " [5.1 3.4 1.5 0.2]\n",
      " [6.6 2.9 4.6 1.3]\n",
      " [5.6 3.  4.1 1.3]\n",
      " [5.9 3.2 4.8 1.8]\n",
      " [6.3 2.3 4.4 1.3]\n",
      " [5.5 3.5 1.3 0.2]\n",
      " [5.1 3.7 1.5 0.4]\n",
      " [4.9 3.1 1.5 0.1]\n",
      " [6.3 2.9 5.6 1.8]\n",
      " [5.8 2.7 4.1 1. ]\n",
      " [7.7 3.8 6.7 2.2]\n",
      " [4.6 3.2 1.4 0.2]]\n",
      "[[4.3 2.  1.  0.1]\n",
      " [4.4 2.2 1.1 0.1]\n",
      " [4.4 2.2 1.2 0.1]\n",
      " [4.4 2.2 1.2 0.1]\n",
      " [4.5 2.3 1.3 0.1]\n",
      " [4.6 2.3 1.3 0.2]\n",
      " [4.6 2.3 1.3 0.2]\n",
      " [4.6 2.3 1.3 0.2]\n",
      " [4.6 2.4 1.3 0.2]\n",
      " [4.7 2.4 1.3 0.2]\n",
      " [4.7 2.4 1.3 0.2]\n",
      " [4.8 2.5 1.4 0.2]\n",
      " [4.8 2.5 1.4 0.2]\n",
      " [4.8 2.5 1.4 0.2]\n",
      " [4.8 2.5 1.4 0.2]\n",
      " [4.8 2.5 1.4 0.2]\n",
      " [4.9 2.5 1.4 0.2]\n",
      " [4.9 2.5 1.4 0.2]\n",
      " [4.9 2.5 1.4 0.2]\n",
      " [4.9 2.6 1.4 0.2]\n",
      " [4.9 2.6 1.4 0.2]\n",
      " [4.9 2.6 1.4 0.2]\n",
      " [5.  2.6 1.4 0.2]\n",
      " [5.  2.6 1.4 0.2]\n",
      " [5.  2.7 1.5 0.2]\n",
      " [5.  2.7 1.5 0.2]\n",
      " [5.  2.7 1.5 0.2]\n",
      " [5.  2.7 1.5 0.2]\n",
      " [5.  2.7 1.5 0.2]\n",
      " [5.  2.7 1.5 0.2]\n",
      " [5.  2.7 1.5 0.2]\n",
      " [5.  2.7 1.5 0.2]\n",
      " [5.1 2.7 1.5 0.2]\n",
      " [5.1 2.8 1.5 0.2]\n",
      " [5.1 2.8 1.5 0.3]\n",
      " [5.1 2.8 1.5 0.3]\n",
      " [5.1 2.8 1.5 0.3]\n",
      " [5.1 2.8 1.6 0.3]\n",
      " [5.1 2.8 1.6 0.3]\n",
      " [5.1 2.8 1.6 0.3]\n",
      " [5.1 2.8 1.6 0.3]\n",
      " [5.2 2.8 1.6 0.4]\n",
      " [5.2 2.8 1.6 0.4]\n",
      " [5.2 2.8 1.6 0.4]\n",
      " [5.2 2.8 1.7 0.4]\n",
      " [5.3 2.8 1.7 0.4]\n",
      " [5.4 2.8 1.7 0.4]\n",
      " [5.4 2.9 1.7 0.4]\n",
      " [5.4 2.9 1.9 0.5]\n",
      " [5.4 2.9 1.9 0.6]\n",
      " [5.4 2.9 3.  1. ]\n",
      " [5.4 2.9 3.3 1. ]\n",
      " [5.5 2.9 3.3 1. ]\n",
      " [5.5 2.9 3.5 1. ]\n",
      " [5.5 2.9 3.5 1. ]\n",
      " [5.5 2.9 3.6 1. ]\n",
      " [5.5 2.9 3.7 1. ]\n",
      " [5.5 3.  3.8 1.1]\n",
      " [5.5 3.  3.9 1.1]\n",
      " [5.6 3.  3.9 1.1]\n",
      " [5.6 3.  3.9 1.2]\n",
      " [5.6 3.  4.  1.2]\n",
      " [5.6 3.  4.  1.2]\n",
      " [5.6 3.  4.  1.2]\n",
      " [5.6 3.  4.  1.2]\n",
      " [5.7 3.  4.  1.3]\n",
      " [5.7 3.  4.1 1.3]\n",
      " [5.7 3.  4.1 1.3]\n",
      " [5.7 3.  4.1 1.3]\n",
      " [5.7 3.  4.2 1.3]\n",
      " [5.7 3.  4.2 1.3]\n",
      " [5.7 3.  4.2 1.3]\n",
      " [5.7 3.  4.2 1.3]\n",
      " [5.8 3.  4.3 1.3]\n",
      " [5.8 3.  4.3 1.3]\n",
      " [5.8 3.  4.4 1.3]\n",
      " [5.8 3.  4.4 1.3]\n",
      " [5.8 3.  4.4 1.3]\n",
      " [5.8 3.  4.4 1.4]\n",
      " [5.8 3.  4.5 1.4]\n",
      " [5.9 3.  4.5 1.4]\n",
      " [5.9 3.  4.5 1.4]\n",
      " [5.9 3.  4.5 1.4]\n",
      " [6.  3.1 4.5 1.4]\n",
      " [6.  3.1 4.5 1.4]\n",
      " [6.  3.1 4.5 1.4]\n",
      " [6.  3.1 4.5 1.5]\n",
      " [6.  3.1 4.6 1.5]\n",
      " [6.  3.1 4.6 1.5]\n",
      " [6.1 3.1 4.6 1.5]\n",
      " [6.1 3.1 4.7 1.5]\n",
      " [6.1 3.1 4.7 1.5]\n",
      " [6.1 3.1 4.7 1.5]\n",
      " [6.1 3.1 4.7 1.5]\n",
      " [6.1 3.2 4.7 1.5]\n",
      " [6.2 3.2 4.8 1.5]\n",
      " [6.2 3.2 4.8 1.5]\n",
      " [6.2 3.2 4.8 1.5]\n",
      " [6.2 3.2 4.8 1.6]\n",
      " [6.3 3.2 4.9 1.6]\n",
      " [6.3 3.2 4.9 1.6]\n",
      " [6.3 3.2 4.9 1.6]\n",
      " [6.3 3.2 4.9 1.7]\n",
      " [6.3 3.2 4.9 1.7]\n",
      " [6.3 3.2 5.  1.8]\n",
      " [6.3 3.2 5.  1.8]\n",
      " [6.3 3.2 5.  1.8]\n",
      " [6.3 3.3 5.  1.8]\n",
      " [6.4 3.3 5.1 1.8]\n",
      " [6.4 3.3 5.1 1.8]\n",
      " [6.4 3.3 5.1 1.8]\n",
      " [6.4 3.3 5.1 1.8]\n",
      " [6.4 3.3 5.1 1.8]\n",
      " [6.4 3.4 5.1 1.8]\n",
      " [6.4 3.4 5.1 1.8]\n",
      " [6.5 3.4 5.1 1.8]\n",
      " [6.5 3.4 5.2 1.9]\n",
      " [6.5 3.4 5.2 1.9]\n",
      " [6.5 3.4 5.3 1.9]\n",
      " [6.5 3.4 5.3 1.9]\n",
      " [6.6 3.4 5.4 1.9]\n",
      " [6.6 3.4 5.4 2. ]\n",
      " [6.7 3.4 5.5 2. ]\n",
      " [6.7 3.4 5.5 2. ]\n",
      " [6.7 3.4 5.5 2. ]\n",
      " [6.7 3.5 5.6 2. ]\n",
      " [6.7 3.5 5.6 2. ]\n",
      " [6.7 3.5 5.6 2.1]\n",
      " [6.7 3.5 5.6 2.1]\n",
      " [6.7 3.5 5.6 2.1]\n",
      " [6.8 3.5 5.6 2.1]\n",
      " [6.8 3.6 5.7 2.1]\n",
      " [6.8 3.6 5.7 2.1]\n",
      " [6.9 3.6 5.7 2.2]\n",
      " [6.9 3.6 5.8 2.2]\n",
      " [6.9 3.7 5.8 2.2]\n",
      " [6.9 3.7 5.8 2.3]\n",
      " [7.  3.7 5.9 2.3]\n",
      " [7.1 3.8 5.9 2.3]\n",
      " [7.2 3.8 6.  2.3]\n",
      " [7.2 3.8 6.  2.3]\n",
      " [7.2 3.8 6.1 2.3]\n",
      " [7.3 3.8 6.1 2.3]\n",
      " [7.4 3.8 6.1 2.3]\n",
      " [7.6 3.9 6.3 2.4]\n",
      " [7.7 3.9 6.4 2.4]\n",
      " [7.7 4.  6.6 2.4]\n",
      " [7.7 4.1 6.7 2.5]\n",
      " [7.7 4.2 6.7 2.5]\n",
      " [7.9 4.4 6.9 2.5]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\efnxqng\\AppData\\Roaming\\Python\\Python37\\site-packages\\sklearn\\preprocessing\\_data.py:2370: UserWarning: n_quantiles (1000) is greater than the total number of samples (150). n_quantiles is set to n_samples.\n",
      "  % (self.n_quantiles, n_samples))\n"
     ]
    }
   ],
   "source": [
    "quantile_transformer = preprocessing.QuantileTransformer(\n",
    "    output_distribution='normal', random_state=0)\n",
    "X_trans = quantile_transformer.fit_transform(X)\n",
    "\n",
    "print(X_train)\n",
    "\n",
    "print(quantile_transformer.quantiles_)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.40824829, -0.40824829,  0.81649658],\n",
       "       [ 1.        ,  0.        ,  0.        ],\n",
       "       [ 0.        ,  0.70710678, -0.70710678]])"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X = [[ 1., -1.,  2.],\n",
    "     [ 2.,  0.,  0.],\n",
    "     [ 0.,  1., -1.]]\n",
    "X_normalized = preprocessing.normalize(X, norm='l2')\n",
    "\n",
    "X_normalized"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Normalizer()"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "normalizer = preprocessing.Normalizer().fit(X)  # fit does nothing\n",
    "normalizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 0.40824829 -0.40824829  0.81649658]\n",
      " [ 1.          0.          0.        ]\n",
      " [ 0.          0.70710678 -0.70710678]]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[-0.70710678,  0.70710678,  0.        ]])"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(normalizer.transform(X))\n",
    "\n",
    "\n",
    "normalizer.transform([[-1.,  1., 0.]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0., 1., 1.]])"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "enc = preprocessing.OrdinalEncoder()\n",
    "X = [['male', 'from US', 'uses Safari'], ['female', 'from Europe', 'uses Firefox']]\n",
    "enc.fit(X)\n",
    "\n",
    "enc.transform([['female', 'from US', 'uses Safari']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1., 0., 0., 1., 0., 1.],\n",
       "       [0., 1., 1., 0., 0., 1.]])"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "enc = preprocessing.OneHotEncoder()\n",
    "X = [['male', 'from US', 'uses Safari'], ['female', 'from Europe', 'uses Firefox']]\n",
    "enc.fit(X)\n",
    "\n",
    "enc.transform([['female', 'from US', 'uses Safari'],\n",
    "               ['male', 'from Europe', 'uses Safari']]).toarray()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[array(['female', 'male'], dtype=object),\n",
       " array(['from Europe', 'from US'], dtype=object),\n",
       " array(['uses Firefox', 'uses Safari'], dtype=object)]"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "enc.categories_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1., 0., 0., 1., 0., 0., 1., 0., 0., 0.]])"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "genders = ['female', 'male']\n",
    "locations = ['from Africa', 'from Asia', 'from Europe', 'from US']\n",
    "browsers = ['uses Chrome', 'uses Firefox', 'uses IE', 'uses Safari']\n",
    "enc = preprocessing.OneHotEncoder(categories=[genders, locations, browsers])\n",
    "# Note that for there are missing categorical values for the 2nd and 3rd\n",
    "# feature\n",
    "X = [['male', 'from US', 'uses Safari'], ['female', 'from Europe', 'uses Firefox']]\n",
    "enc.fit(X)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "enc.transform([['female', 'from Asia', 'uses Chrome']]).toarray()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1., 0., 0., 0., 0., 0.]])"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "enc = preprocessing.OneHotEncoder(handle_unknown='ignore')\n",
    "X = [['male', 'from US', 'uses Safari'], ['female', 'from Europe', 'uses Firefox']]\n",
    "enc.fit(X)\n",
    "\n",
    "enc.transform([['female', 'from Asia', 'uses Chrome']]).toarray()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0. 1. 0. 1. 0. 1.]\n",
      " [1. 0. 1. 0. 1. 0.]]\n",
      "[[1. 1. 1.]\n",
      " [0. 0. 0.]]\n",
      "[array(['female', 'male'], dtype=object), array(['from Europe', 'from US'], dtype=object), array(['uses Firefox', 'uses Safari'], dtype=object)]\n"
     ]
    }
   ],
   "source": [
    "X = [['male', 'from US', 'uses Safari'],\n",
    "     ['female', 'from Europe', 'uses Firefox']]\n",
    "\n",
    "drop_enc = preprocessing.OneHotEncoder().fit(X)\n",
    "\n",
    "print(drop_enc.transform(X).toarray())\n",
    "\n",
    "\n",
    "\n",
    "drop_enc = preprocessing.OneHotEncoder(drop='first').fit(X)\n",
    "\n",
    "print(drop_enc.transform(X).toarray())\n",
    "\n",
    "\n",
    "print(drop_enc.categories_)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Input contains NaN",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-37-ae70d82410af>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      2\u001b[0m      \u001b[1;33m[\u001b[0m\u001b[1;34m'female'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m      [np.nan, 'Firefox']]\n\u001b[1;32m----> 4\u001b[1;33m \u001b[0menc\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpreprocessing\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mOneHotEncoder\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mhandle_unknown\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'error'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      5\u001b[0m \u001b[0menc\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcategories_\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      6\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python37\\site-packages\\sklearn\\preprocessing\\_encoders.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, X, y)\u001b[0m\n\u001b[0;32m    383\u001b[0m         \"\"\"\n\u001b[0;32m    384\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_validate_keywords\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 385\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_fit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mhandle_unknown\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mhandle_unknown\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    386\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdrop_idx_\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_compute_drop_idx\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    387\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python37\\site-packages\\sklearn\\preprocessing\\_encoders.py\u001b[0m in \u001b[0;36m_fit\u001b[1;34m(self, X, handle_unknown)\u001b[0m\n\u001b[0;32m     72\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     73\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m_fit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mhandle_unknown\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'error'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 74\u001b[1;33m         \u001b[0mX_list\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mn_samples\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mn_features\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_check_X\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     75\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     76\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcategories\u001b[0m \u001b[1;33m!=\u001b[0m \u001b[1;34m'auto'\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python37\\site-packages\\sklearn\\preprocessing\\_encoders.py\u001b[0m in \u001b[0;36m_check_X\u001b[1;34m(self, X)\u001b[0m\n\u001b[0;32m     41\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mhasattr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'iloc'\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mand\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'ndim'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;36m2\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     42\u001b[0m             \u001b[1;31m# if not a dataframe, do normal check_array validation\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 43\u001b[1;33m             \u001b[0mX_temp\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcheck_array\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     44\u001b[0m             if (not hasattr(X, 'dtype')\n\u001b[0;32m     45\u001b[0m                     and np.issubdtype(X_temp.dtype, np.str_)):\n",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python37\\site-packages\\sklearn\\utils\\validation.py\u001b[0m in \u001b[0;36minner_f\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     70\u001b[0m                           FutureWarning)\n\u001b[0;32m     71\u001b[0m         \u001b[0mkwargs\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m{\u001b[0m\u001b[0mk\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0marg\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mk\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0marg\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mzip\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msig\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mparameters\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0margs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m}\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 72\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mf\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     73\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0minner_f\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     74\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python37\\site-packages\\sklearn\\utils\\validation.py\u001b[0m in \u001b[0;36mcheck_array\u001b[1;34m(array, accept_sparse, accept_large_sparse, dtype, order, copy, force_all_finite, ensure_2d, allow_nd, ensure_min_samples, ensure_min_features, estimator)\u001b[0m\n\u001b[0;32m    643\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mforce_all_finite\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    644\u001b[0m             _assert_all_finite(array,\n\u001b[1;32m--> 645\u001b[1;33m                                allow_nan=force_all_finite == 'allow-nan')\n\u001b[0m\u001b[0;32m    646\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    647\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mensure_min_samples\u001b[0m \u001b[1;33m>\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python37\\site-packages\\sklearn\\utils\\validation.py\u001b[0m in \u001b[0;36m_assert_all_finite\u001b[1;34m(X, allow_nan, msg_dtype)\u001b[0m\n\u001b[0;32m    102\u001b[0m     \u001b[1;32melif\u001b[0m \u001b[0mX\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdtype\u001b[0m \u001b[1;33m==\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdtype\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'object'\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mand\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mallow_nan\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    103\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0m_object_dtype_isnan\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0many\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 104\u001b[1;33m             \u001b[1;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"Input contains NaN\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    105\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    106\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: Input contains NaN"
     ]
    }
   ],
   "source": [
    "X = [['male', 'Safari'],\n",
    "     ['female', None],\n",
    "     [np.nan, 'Firefox']]\n",
    "enc = preprocessing.OneHotEncoder(handle_unknown='error').fit(X)\n",
    "enc.categories_\n",
    "\n",
    "\n",
    "enc.transform(X).toarray()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = np.array([[ -3., 5., 15 ],\n",
    "              [  0., 6., 14 ],\n",
    "              [  6., 3., 11 ]])\n",
    "est = preprocessing.KBinsDiscretizer(n_bins=[3, 2, 2], encode='ordinal').fit(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0., 1., 1.],\n",
       "       [1., 1., 1.],\n",
       "       [2., 0., 0.]])"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "est.transform(X)      "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[infant, kid, teen, adult, senior citizen]\n",
       "Categories (5, object): [infant < kid < teen < adult < senior citizen]"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "bins = [0, 1, 13, 20, 60, np.inf]\n",
    "labels = ['infant', 'kid', 'teen', 'adult', 'senior citizen']\n",
    "transformer = preprocessing.FunctionTransformer(\n",
    "    pd.cut, kw_args={'bins': bins, 'labels': labels, 'retbins': False}\n",
    ")\n",
    "X = np.array([0.2, 2, 15, 25, 97])\n",
    "transformer.fit_transform(X)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1., 0., 1.],\n",
       "       [1., 0., 0.],\n",
       "       [0., 1., 0.]])"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X = [[ 1., -1.,  2.],\n",
    "     [ 2.,  0.,  0.],\n",
    "     [ 0.,  1., -1.]]\n",
    "\n",
    "binarizer = preprocessing.Binarizer().fit(X)  # fit does nothing\n",
    "binarizer\n",
    "\n",
    "\n",
    "binarizer.transform(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0 0 0]\n",
      " [0 1 1]\n",
      " [1 0 1]\n",
      " [1 1 1]]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[0.351202  , 0.35133743],\n",
       "       [0.28166326, 0.28158611],\n",
       "       [0.26812454, 0.26637602],\n",
       "       [0.23693656, 0.236081  ]])"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "from sklearn.neural_network import BernoulliRBM\n",
    "X = np.array([[0, 0, 0], [0, 1, 1], [1, 0, 1], [1, 1, 1]])\n",
    "model = BernoulliRBM(n_components=2)\n",
    "model.fit(X)\n",
    "\n",
    "print(X)\n",
    "\n",
    "model.transform(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0, 0, 0],\n",
       "       [0, 0, 0],\n",
       "       [0, 0, 0],\n",
       "       [0, 0, 0]])"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "binarizer = preprocessing.Binarizer(threshold=1.1)\n",
    "binarizer.transform(X)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0 1]\n",
      " [2 3]\n",
      " [4 5]]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[ 1.,  0.,  1.,  0.,  0.,  1.],\n",
       "       [ 1.,  2.,  3.,  4.,  6.,  9.],\n",
       "       [ 1.,  4.,  5., 16., 20., 25.]])"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "from sklearn.preprocessing import PolynomialFeatures\n",
    "X = np.arange(6).reshape(3, 2)\n",
    "print(X)\n",
    "\n",
    "\n",
    "\n",
    "poly = PolynomialFeatures(2)\n",
    "poly.fit_transform(X)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0 1 2]\n",
      " [3 4 5]\n",
      " [6 7 8]]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[  1.,   0.,   1.,   2.,   0.,   0.,   2.,   0.],\n",
       "       [  1.,   3.,   4.,   5.,  12.,  15.,  20.,  60.],\n",
       "       [  1.,   6.,   7.,   8.,  42.,  48.,  56., 336.]])"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X = np.arange(9).reshape(3, 3)\n",
    "print(X)\n",
    "\n",
    "\n",
    "\n",
    "poly = PolynomialFeatures(degree=3, interaction_only=True)\n",
    "poly.fit_transform(X)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
